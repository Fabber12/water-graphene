{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d218727",
   "metadata": {},
   "source": [
    "# Kapitza Resistance Post-Processing\n",
    "Created by F. Tarulli – 5 Jul 2025  \n",
    "Analyzes graphene–water transient runs to extract the Kapitza resistance and plot **G<sub>k</sub> = 1/R<sub>k</sub>** for oxidation levels 0–80 %.\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "1. **Load replica data**  \n",
    "   - slab temperatures (`system_graph.txt`, `system_h2o.txt`)  \n",
    "   - graphene energies (`potential_graph.txt`, `kinetic_graph.txt`)  \n",
    "   - temperature profile (`temp_chunk_bias_1A.out`)\n",
    "\n",
    "2. **Concatenate & align** 10 replicas\n",
    "\n",
    "3. **Linear fit** of  E<sub>tot,graph</sub> vs. ∫ΔTdt to obtain slope *m*  \n",
    "   ⇒ R<sub>k</sub> = *Area*/m\n",
    "\n",
    "4. **Plot** G<sub>k</sub> as a function of oxidation degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3149c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.constants import N_A\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize_scalar\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AREA = {\n",
    "    0 : 2 * 73.2e-10 * 74.3e-10,\n",
    "    5 : 2 * 73.1e-10 * 74.4e-10,\n",
    "    10 : 2 * 73.1e-10 * 74.3e-10,\n",
    "    20 : 2 * 73.3e-10 * 74.0e-10,\n",
    "    40 : 2 * 72.8e-10 * 73.9e-10,\n",
    "    60 :  2 * 72.5e-10 * 73.7e-10,\n",
    "    80 : 2 * 72.7e-10 * 73.9e-10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Tgraph_chunks(base_remote_path, file_name, k):\n",
    "    Temp_chunks = []\n",
    "    with open(f'{base_remote_path}/slab_position_verify.txt', 'r') as file:\n",
    "        for _ in range(3):\n",
    "            next(file)\n",
    "        line = next(file).strip().split()\n",
    "        Nchunks_tot = int(line[1])\n",
    "    with open(f'{base_remote_path}/{file_name}', 'r') as file:\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                # Skip the first 4 lines for the first chunk\n",
    "                for _ in range(4):\n",
    "                    next(file)\n",
    "            else:\n",
    "                # Skip the first 2 lines for subsequent chunks\n",
    "                next(file)\n",
    "            \n",
    "            # Read the next N lines\n",
    "            chunk = []\n",
    "            for _ in range(Nchunks_tot):\n",
    "                line = next(file).strip()\n",
    "                values = list(map(float, line.split()))\n",
    "                chunk.append(values)\n",
    "            \n",
    "            Temp_chunks.append(np.array(chunk))\n",
    "    return Temp_chunks, Nchunks_tot\n",
    "\n",
    "def process_chunks(Temp_chunks, Nchunks_tot, Nchunks, slab_skip=3): # Nchunks_tot: total chunks; Nchunks: target chunks for temp evaluatation\n",
    "    k = len(Temp_chunks)\n",
    "    T_slab_positive = np.zeros(k)\n",
    "    T_slab_negative = np.zeros(k)\n",
    "    T_bulk_chunk = np.zeros(k)\n",
    "\n",
    "    # elem_transient=5000 # skip first 50 ps\n",
    "\n",
    "    for i in range(k):\n",
    "        up = Nchunks_tot // 2 + int(slab_skip) \n",
    "        down = Nchunks_tot // 2 - 1 - int(slab_skip) \n",
    "        \n",
    "        # Average layers above graphene\n",
    "        positive_layers = [Temp_chunks[i][up + j, 1] for j in range(Nchunks-slab_skip)]\n",
    "        T_slab_positive[i] = np.mean(positive_layers)\n",
    "        # if i==30000:\n",
    "        #     print(positive_layers) # test\n",
    "        \n",
    "        # Average layers below graphene\n",
    "        negative_layers = [Temp_chunks[i][down - j, 1] for j in range(Nchunks-slab_skip)]\n",
    "        T_slab_negative[i] = np.mean(negative_layers)\n",
    "        # if i==30000:\n",
    "        #     plt.plot(negative_layers)\n",
    "\n",
    "        # Average temperature across the entire chunk\n",
    "        T_bulk_chunk[i] = np.mean(Temp_chunks[i][:, 1])\n",
    "    \n",
    "    # Mean temperature of both slabs\n",
    "    T_slab_mean = np.mean(np.vstack((T_slab_positive, T_slab_negative)), axis=0)\n",
    "    return T_slab_positive, T_slab_negative, T_bulk_chunk, T_slab_mean\n",
    "\n",
    "\n",
    "def pw_lin_exp_const(t, t0, t1, m, c, lam, d):\n",
    "    lin = m*t + c\n",
    "    exp_seg = d + (m*t0 + c - d)*np.exp(-lam*(t - t0))\n",
    "    const = d\n",
    "    return np.where(t < t0,\n",
    "                    lin,\n",
    "                    np.where(t < t1,\n",
    "                             exp_seg,\n",
    "                             const))\n",
    "\n",
    "def slope_one(x, y):\n",
    "    t0g = x[np.abs(y - y.mean()).argmin()]\n",
    "    t1g = x[(x > t0g)].mean()\n",
    "    p0  = [t0g, t1g, 0.0, y[0], 1.0, y[-1]]\n",
    "    lb  = [x.min(), t0g+1e-6, -np.inf, -np.inf, 1e-6, y.min()]\n",
    "    ub  = [x.max(), x.max(),   np.inf,  np.inf,  1e3, y.max()]\n",
    "    popt, pcov, infodict, mesg, ier    = curve_fit(pw_lin_exp_const, x, y, p0=p0,\n",
    "                        bounds=(lb, ub), max_nfev=5_000, full_output=True)\n",
    "    t0, t1, m, c, lam, d = popt\n",
    "    d_endexp = d + (m*t0 + c - d)*np.exp(-lam*(t1 - t0))\n",
    "    if np.abs(d-d_endexp) > 5e-1:\n",
    "        raise ValueError(\"NO\")\n",
    "    if (m*t0 + c - d) > (- m*t0 ):\n",
    "        raise ValueError(\"NO\")\n",
    "    return popt[0], popt[2], mesg, ier \n",
    "\n",
    "\n",
    "def find_breakpoint_iterative(x, y, min_points=10, maxiter=100, penalty_npoint=0.1, penalty_const=0.1):\n",
    "    def mse_break(x0):\n",
    "        idx = np.searchsorted(x, x0, 'right')\n",
    "        c0 = np.mean(y[:10])\n",
    "        if idx < min_points:\n",
    "            idx = min_points\n",
    "            return np.float64(1e100)\n",
    "        xi, yi = x[:idx], y[:idx]\n",
    "        yl = y[idx:]\n",
    "        m, c = np.polyfit(xi, yi, 1)\n",
    "        const_par = m*x0 + c0\n",
    "        return np.sum((yi - (m*xi + c0))**2) + penalty_const*np.sum((yl - const_par)**2)  + 0*np.abs(np.log(len(x)/len(xi)))*penalty_npoint\n",
    "\n",
    "    res = minimize_scalar(\n",
    "        mse_break,\n",
    "        bounds=(x[min_points], x[-1]),\n",
    "        method='bounded',\n",
    "        options={'maxiter': maxiter}\n",
    "    )\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c08b7",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ALL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f86841",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBulk = False\n",
    "LOAD = True\n",
    "h_slab = 9 # Angstrom\n",
    "\n",
    "for oxid in [0, 5, 10 ,20 ,40 ,60 ,80]:\n",
    "    c_rep = 0\n",
    "    temps_w = []\n",
    "    temps_g = []\n",
    "    pe_g = []\n",
    "    ke_g = []\n",
    "    etot = []\n",
    "    print(f\" OXID={oxid:3d} \".center(100, \"=\"))\n",
    "    for rep in tqdm(range(1,11), desc='loads reps', total=10) :\n",
    "        try:\n",
    "            root = Path(f'lammps/transient/{oxid:d}%')\n",
    "            base_remote_path = os.path.join(root, f'Transient/graph{oxid:d}%_{rep:d}')\n",
    "            file_liquid = 'system_h2o.txt'\n",
    "            file_nanoparticles = 'system_graph.txt'\n",
    "            file_chunk = 'temp_chunk_bias_1A.out'\n",
    "            file_slabverify = 'slab_position_verify.txt' \n",
    "            file_Pot = 'potential_graph.txt'\n",
    "            file_Kin = 'kinetic_graph.txt'\n",
    "            temps_g.append(pd.read_csv(os.path.join(base_remote_path, file_nanoparticles), sep=r'\\s+',  skiprows=2, names=[\"step\", f\"temp_{c_rep:d}\"]))\n",
    "            if TBulk:\n",
    "                temps_w.append(pd.read_csv(os.path.join(base_remote_path, file_liquid), sep=r'\\s+', skiprows=2, names=[\"step\", f\"temp_{c_rep:d}\"]))\n",
    "            elif not LOAD: \n",
    "                Tchunks, tot_chunks = read_Tgraph_chunks(base_remote_path, file_chunk, temps_g[0].shape[0])\n",
    "                T_slab_positive, T_slab_negative, T_bulk_chunk, T_slab_mean = process_chunks(Tchunks,tot_chunks,h_slab)\n",
    "                df_slab = pd.DataFrame({\"step\": temps_g[-1][\"step\"].values, f\"temp_{c_rep:d}\": T_slab_mean })\n",
    "                temps_w.append(df_slab)\n",
    "            pe_g.append(pd.read_csv(os.path.join(base_remote_path, file_Pot), sep=r'\\s+', skiprows=2, names=[\"step\", f\"pe_{c_rep:d}\"]))\n",
    "            ke_g.append(pd.read_csv(os.path.join(base_remote_path, file_Kin), sep=r'\\s+', skiprows=2, names=[\"step\", f\"ke_{c_rep:d}\"]))  \n",
    "            etot.append( pd.DataFrame(data={\"step\": pe_g[-1][\"step\"], f\"etot_{c_rep:d}\": pe_g[-1][f\"pe_{c_rep:d}\"] + ke_g[-1][f\"ke_{c_rep:d}\"]}) )\n",
    "            c_rep +=1\n",
    "        except Exception:\n",
    "            print(\"Erro in rep=\", rep)\n",
    "    rep_Tgr = pd.concat(temps_g, axis=1)\n",
    "    rep_etot = pd.concat(etot, axis=1)\n",
    "    numpy_dir = os.path.join(f'{root}','numpy')\n",
    "\n",
    "    if not Path(numpy_dir).exists():\n",
    "            os.mkdir(numpy_dir)\n",
    "\n",
    "    if TBulk:\n",
    "        LOAD = False\n",
    "    if not LOAD:\n",
    "        rep_Tw = pd.concat(temps_w, axis=1)\n",
    "        if not TBulk:\n",
    "            rep_Tw.to_pickle(os.path.join(numpy_dir,f'rep_Tw_{h_slab}A.pkl'))\n",
    "            print(\"saved in: \",os.path.join(numpy_dir,f'rep_Tw_{h_slab}A.pkl'))\n",
    "    else:\n",
    "        rep_Tw = pd.read_pickle(os.path.join(numpy_dir,f'rep_Tw_{h_slab}A.pkl'))\n",
    "\n",
    "    DATA_ALL[oxid] = {\n",
    "        \"Tw\": rep_Tw.copy(),\n",
    "        \"Tgr\": rep_Tgr.copy(),\n",
    "        \"etot\": rep_etot.copy(),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37246c17",
   "metadata": {},
   "source": [
    "# CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCAT_ALL_DATA = {}\n",
    "N_rep = 10\n",
    "for oxid, data in tqdm(DATA_ALL.items(),desc=\"concat data\", total=len(DATA_ALL)):\n",
    "   \n",
    "    CONCAT_ALL_DATA[oxid] = {\n",
    "        \"time_s\": data[\"Tw\"].iloc[:,0].values * 1e-15, \n",
    "        \"Tw\": np.column_stack([data[\"Tw\"][f\"temp_{i}\"].values for i in range(N_rep)])[5000:],\n",
    "        \"Tgr\": np.column_stack([data[\"Tgr\"][f\"temp_{i}\"].values for i in range(N_rep)])[5000:],\n",
    "        \"etot\": np.column_stack([data[\"etot\"][f\"etot_{i}\"].values for i in range(N_rep)])[5000:]    \n",
    "    }\n",
    "    Nt = CONCAT_ALL_DATA[oxid][\"time_s\"].shape[0]\n",
    "    int_t_rep = np.zeros((Nt, N_rep))\n",
    "    for i in range(N_rep):\n",
    "        dt_i = data[\"Tgr\"].loc[:, f\"temp_{i}\"].values - data[\"Tw\"].loc[:, f\"temp_{i}\"].values\n",
    "        int_t_rep[1:, i] = cumulative_trapezoid(dt_i, CONCAT_ALL_DATA[oxid][\"time_s\"])\n",
    "    CONCAT_ALL_DATA[oxid]['integral'] = int_t_rep[5000:] - int_t_rep[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd0b37",
   "metadata": {},
   "source": [
    "# $R_K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPE_ALL = {}\n",
    "SLOPE_ensavg_ALL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76106f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for oxid, data in CONCAT_ALL_DATA.items():\n",
    "    start_s = time()\n",
    "    print(f\" OX STATE {oxid:3d} \".center(120, \"=\"))\n",
    "    diffT = data['Tgr'] - data['Tw']\n",
    "    integral = data['integral']\n",
    "    etot = data['etot']\n",
    "    scaleT = diffT.std()\n",
    "    scaleE = etot.std()\n",
    "    scaleInt = integral.std()\n",
    "    print(\"searchin t0 ..\", end='')\n",
    "    N_each = integral.shape[0] // 10\n",
    "    t0_all = []\n",
    "    m_all = []\n",
    "    for i in tqdm(range(10), total=10):\n",
    "        t0 = find_breakpoint_iterative(integral[:,i]/scaleInt, etot[:,i]/scaleE, min_points=9, maxiter=500, penalty_npoint=2, penalty_const=1)\n",
    "        integ_temp = integral[:,i]/scaleInt\n",
    "        if len(integ_temp[integ_temp<t0]) < 10:\n",
    "            continue\n",
    "        t0_all.append(t0*scaleInt)\n",
    "        # m_all.append(m)\n",
    "    print(\"done!\")\n",
    "    print(f\"\\t t0={t0:1.3e}\")\n",
    "    t0_min = np.min(t0_all)\n",
    "\n",
    "    print(f\"t0_min = {t0_min:1.3e}\")\n",
    "    print(\"linear fit ..\", end='')\n",
    "    x_fit = integral[integral<t0_min]\n",
    "    y_fit = etot[integral<t0_min]\n",
    "    x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "    robust_model = sm.OLS(y_fit, x_fit)\n",
    "    results = robust_model.fit()\n",
    "    slope = results.params[1]\n",
    "    slope_reps = []\n",
    "    all_fit = []\n",
    "    for i in tqdm(range(10), total=10):\n",
    "        integral_rep = integral[:,i]\n",
    "        etot_rep = etot[:,i]\n",
    "        t0_i = t0_all[i] \n",
    "        x_fit = integral_rep[integral_rep<t0_min]\n",
    "        y_fit = etot_rep[integral_rep<t0_min]\n",
    "        x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "        robust_model = sm.OLS(y_fit, x_fit)\n",
    "        results_rep = robust_model.fit()\n",
    "        all_fit.append(\n",
    "            results_rep\n",
    "        )\n",
    "        slope_reps.append( results_rep.params[1] )\n",
    "\n",
    "    intercept_reps = [res.params[0] for res in all_fit]\n",
    "    slope_reps     = [res.params[1] for res in all_fit]\n",
    "    a_bar = np.mean(intercept_reps)\n",
    "    m_bar = np.mean(slope_reps)\n",
    "    x_pred = np.linspace(integral.min(), t0_min, 100)\n",
    "    y_med = a_bar + m_bar * x_pred\n",
    "    plt.plot(x_pred, y_med, color='r', zorder =20 , lw=4)\n",
    "\n",
    "    slope = np.mean(slope_reps)\n",
    "\n",
    "    N_rep = len(slope_reps)          # 10\n",
    "    slope_se   = np.std(slope_reps, ddof=1) / np.sqrt(N_rep)   # standard error\n",
    "    slope_err  = 1.96 * slope_se \n",
    "    \n",
    "        \n",
    "    # }\n",
    "    SLOPE_ALL[oxid] = {\n",
    "        \"Rk_m\" : - AREA[oxid]/ (slope* 4184 / N_A),\n",
    "        \"Rk_e\" : AREA[oxid]/ (4184 / N_A) / (slope)**2 * slope_err,\n",
    "    }\n",
    "    \n",
    "    SLOPE_ALL[oxid][\"Rk_rse\"] = SLOPE_ALL[oxid][\"Rk_e\"] / abs(SLOPE_ALL[oxid][\"Rk_m\"])\n",
    "    SLOPE_ALL[oxid][\"Gk_m\"] = 1/SLOPE_ALL[oxid][\"Rk_m\"]\n",
    "    SLOPE_ALL[oxid][\"Gk_e\"] = SLOPE_ALL[oxid][\"Rk_e\"] / SLOPE_ALL[oxid][\"Rk_m\"]**2\n",
    "    print(f\"\\t m = {slope:1.3e} +/- {slope_err:1.3e}\")\n",
    "    print(f\"\\t Rk = {SLOPE_ALL[oxid][\"Rk_m\"]:1.3e} +/- {SLOPE_ALL[oxid][\"Rk_e\"]:1.3e} (i.e )  {SLOPE_ALL[oxid][\"Rk_rse\"]}\")\n",
    "    print(f\"\\t Gk = {SLOPE_ALL[oxid][\"Gk_m\"]:1.3e} +/- {SLOPE_ALL[oxid][\"Gk_e\"]:1.3e}\")\n",
    "    b = results.params\n",
    "    x_pred = np.linspace(integral.min(), t0_min, 10)\n",
    "    pred = results.get_prediction(sm.add_constant(x_pred))\n",
    "    y_pred = pred.predicted\n",
    "    iv_l_ols = pred.summary_frame()[\"mean_ci_lower\"]\n",
    "    iv_u_ols = pred.summary_frame()[\"mean_ci_upper\"]\n",
    "    print(\"done!\")\n",
    "\n",
    "    # plot\n",
    "    indx0  = np.where(integral[:,0]<t0_min)[0]\n",
    "    int_rep_mean = integral[indx0, :].mean(axis=1)\n",
    "    etot_mean = etot[indx0, :].mean(axis=1)\n",
    "    plt.plot(int_rep_mean,etot_mean, color='y')\n",
    "\n",
    "    slope_ensam_avg = - AREA[oxid]/ (np.polyfit(int_rep_mean,etot_mean,1)[0] * 4184 / N_A)\n",
    "    print(f\"R_ens_avg = {slope_ensam_avg}\")\n",
    "    SLOPE_ensavg_ALL[oxid] = {\n",
    "        \"Rk_m\" : - AREA[oxid]/ (slope* 4184 / N_A)  \n",
    "    }\n",
    "    SLOPE_ensavg_ALL[oxid][\"Gk_m\"] = 1/SLOPE_ensavg_ALL[oxid][\"Rk_m\"]\n",
    "    n=0\n",
    "    for res_fint in all_fit:\n",
    "        indx0 = integral[:, n] < t0_min\n",
    "        pred = res_fint.get_prediction(sm.add_constant(x_pred))\n",
    "        y_pred_i = pred.predicted\n",
    "        plt.plot(x_pred,y_pred_i, color='k', ls=\":\")\n",
    "        plt.scatter(integral[indx0,n], etot[indx0,n], s=4, alpha=.3, label = f'Replicate {n}')\n",
    "        n += 1\n",
    "    # plt.legend(loc='best', fontsize='small')    \n",
    "    plt.show()\n",
    "    # plt.xlim(integral.min(), t0_min)\n",
    "    end_time =  time()\n",
    "    print(f\"elalpesed time {end_time-start_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = [[oxid, data[\"Gk_m\"], data[\"Gk_e\"]] for oxid, data in SLOPE_ALL.items()]\n",
    "data_all = np.asarray(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.errorbar(data_all[:,0], data_all[:,1], yerr=data_all[:,2],)\n",
    "# plt.scatter(data_all[:,0], data_all[:,1],c='b',marker='o')\n",
    "x_fit = data_all[:,0]\n",
    "y_fit = data_all[:,1]\n",
    "x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "weight = data_all[:,1]**2/data_all[:,2]**2\n",
    "weight /= weight.mean()\n",
    "robust_model = sm.GLM(y_fit, x_fit, var_weights=weight)\n",
    "results = robust_model.fit()\n",
    "x_pred = np.linspace(data_all[:,0].min(), data_all[:,0].max(), 100)\n",
    "pred = results.get_prediction(sm.add_constant(x_pred))\n",
    "y_pred = pred.predicted\n",
    "iv_l_ols = pred.summary_frame()[\"mean_ci_lower\"]\n",
    "iv_u_ols = pred.summary_frame()[\"mean_ci_upper\"]\n",
    "# plt.fill_between(x_pred, iv_l_ols, iv_u_ols, alpha=.3, color='k')\n",
    "# plt.plot(x_pred, y_pred, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd09da3",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435c331",
   "metadata": {},
   "source": [
    "## Gk vs oxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleup = 1.25\n",
    "fig = plt.figure(figsize=(3.3*scaleup, 2*scaleup), dpi=250)\n",
    "\n",
    "with plt.style.context(\"style.matplot\"):    #import your own style\n",
    "    grid = fig.add_gridspec(1,1, top=.99, right=.99, bottom=.18)\n",
    "    ax = fig.add_subplot(grid[0] )\n",
    "    # plt.fill_between(df[\"time\"], df[\"CA\"]-df[\"std\"], df[\"CA\"]+df[\"std\"], alpha=.5)\n",
    "    plt1 = ax.errorbar(data_all[:,0], data_all[:,1]*1e-8, yerr=data_all[:,2]*1e-8, capsize=2.2, fmt='o', markersize=3.2, zorder=11, color=\"#282222\", lw=.5, label=\"Instantaneous value\")\n",
    "    plt2 = ax.fill_between(x_pred, iv_l_ols*1e-8, iv_u_ols*1e-8, alpha=.4, zorder=10, color=\"#5678E7\")\n",
    "    plt3 = ax.plot(x_pred, y_pred*1e-8, '-', lw=1.3, zorder=10, color='#5678E7')\n",
    "    ax.legend([plt1, (plt2,plt3[0])], (\"Simulation Data\", \"Linear regression (with 95% CB)\"))\n",
    "    ax.set_xlabel(\"Oxidation (%)\")\n",
    "    \n",
    "    ax.set_ylabel(r\"$\\mathregular{1/R_k}$ (x10$^8$ W/m$^2$K)\")\n",
    "fig.savefig(\"fig_Gk-oxid.png\", dpi=400)\n",
    "fig.savefig(\"fig_Gk-oxid.pdf\", dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
