{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d218727",
   "metadata": {},
   "source": [
    "Final protocol 5/7/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3149c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.constants import N_A\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AREA = {\n",
    "    0 : 2 * 73.2e-10 * 74.3e-10,\n",
    "    5 : 2 * 73.1e-10 * 74.4e-10,\n",
    "    10 : 2 * 73.1e-10 * 74.3e-10,\n",
    "    20 : 2 * 73.3e-10 * 74.0e-10,\n",
    "    40 : 2 * 72.8e-10 * 73.9e-10,\n",
    "    60 :  2 * 72.5e-10 * 73.7e-10,\n",
    "    80 : 2 * 72.7e-10 * 73.9e-10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Tgraph_chunks(base_remote_path, file_name, k):\n",
    "    Temp_chunks = []\n",
    "    with open(f'{base_remote_path}/slab_position_verify.txt', 'r') as file:\n",
    "        for _ in range(3):\n",
    "            next(file)\n",
    "        line = next(file).strip().split()\n",
    "        Nchunks_tot = int(line[1])\n",
    "    with open(f'{base_remote_path}/{file_name}', 'r') as file:\n",
    "        for i in range(k):\n",
    "            if i == 0:\n",
    "                # Skip the first 4 lines for the first chunk\n",
    "                for _ in range(4):\n",
    "                    next(file)\n",
    "            else:\n",
    "                # Skip the first 2 lines for subsequent chunks\n",
    "                next(file)\n",
    "            \n",
    "            # Read the next N lines\n",
    "            chunk = []\n",
    "            for _ in range(Nchunks_tot):\n",
    "                line = next(file).strip()\n",
    "                values = list(map(float, line.split()))\n",
    "                chunk.append(values)\n",
    "            \n",
    "            Temp_chunks.append(np.array(chunk))\n",
    "    return Temp_chunks, Nchunks_tot\n",
    "\n",
    "def process_chunks(Temp_chunks, Nchunks_tot, Nchunks, slab_skip=3): # Nchunks_tot: total chunks; Nchunks: target chunks for temp evaluatation\n",
    "    k = len(Temp_chunks)\n",
    "    T_slab_positive = np.zeros(k)\n",
    "    T_slab_negative = np.zeros(k)\n",
    "    T_bulk_chunk = np.zeros(k)\n",
    "\n",
    "    # elem_transient=5000 # skip first 50 ps\n",
    "\n",
    "    for i in range(k):\n",
    "        up = Nchunks_tot // 2 + int(slab_skip) \n",
    "        down = Nchunks_tot // 2 - 1 - int(slab_skip) \n",
    "        \n",
    "        # Average layers above graphene\n",
    "        positive_layers = [Temp_chunks[i][up + j, 1] for j in range(Nchunks-slab_skip)]\n",
    "        T_slab_positive[i] = np.mean(positive_layers)\n",
    "        # if i==30000:\n",
    "        #     print(positive_layers) # test\n",
    "        \n",
    "        # Average layers below graphene\n",
    "        negative_layers = [Temp_chunks[i][down - j, 1] for j in range(Nchunks-slab_skip)]\n",
    "        T_slab_negative[i] = np.mean(negative_layers)\n",
    "        # if i==30000:\n",
    "        #     plt.plot(negative_layers)\n",
    "\n",
    "        # Average temperature across the entire chunk\n",
    "        T_bulk_chunk[i] = np.mean(Temp_chunks[i][:, 1])\n",
    "    \n",
    "    # Mean temperature of both slabs\n",
    "    T_slab_mean = np.mean(np.vstack((T_slab_positive, T_slab_negative)), axis=0)\n",
    "    return T_slab_positive, T_slab_negative, T_bulk_chunk, T_slab_mean\n",
    "\n",
    "\n",
    "def pw_lin_exp_const(t, t0, t1, m, c, lam, d):\n",
    "    lin = m*t + c\n",
    "    exp_seg = d + (m*t0 + c - d)*np.exp(-lam*(t - t0))\n",
    "    const = d\n",
    "    return np.where(t < t0,\n",
    "                    lin,\n",
    "                    np.where(t < t1,\n",
    "                             exp_seg,\n",
    "                             const))\n",
    "\n",
    "def slope_one(x, y):\n",
    "    t0g = x[np.abs(y - y.mean()).argmin()]\n",
    "    t1g = x[(x > t0g)].mean()\n",
    "    p0  = [t0g, t1g, 0.0, y[0], 1.0, y[-1]]\n",
    "    lb  = [x.min(), t0g+1e-6, -np.inf, -np.inf, 1e-6, y.min()]\n",
    "    ub  = [x.max(), x.max(),   np.inf,  np.inf,  1e3, y.max()]\n",
    "    popt, pcov, infodict, mesg, ier    = curve_fit(pw_lin_exp_const, x, y, p0=p0,\n",
    "                        bounds=(lb, ub), max_nfev=5_000, full_output=True)\n",
    "    t0, t1, m, c, lam, d = popt\n",
    "    d_endexp = d + (m*t0 + c - d)*np.exp(-lam*(t1 - t0))\n",
    "    if np.abs(d-d_endexp) > 5e-1:\n",
    "        raise ValueError(\"NO\")\n",
    "    if (m*t0 + c - d) > (- m*t0 ):\n",
    "        raise ValueError(\"NO\")\n",
    "    return popt[0], popt[2], mesg, ier \n",
    "\n",
    "\n",
    "def find_breakpoint_iterative(x, y, min_points=10, maxiter=100, penalty_npoint=0.1, penalty_const=0.1):\n",
    "    def mse_break(x0):\n",
    "        idx = np.searchsorted(x, x0, 'right')\n",
    "        c0 = np.mean(y[:10])\n",
    "        if idx < min_points:\n",
    "            idx = min_points\n",
    "            return np.float64(1e100)\n",
    "        xi, yi = x[:idx], y[:idx]\n",
    "        yl = y[idx:]\n",
    "        m, c = np.polyfit(xi, yi, 1)\n",
    "        const_par = m*x0 + c0\n",
    "        return np.sum((yi - (m*xi + c0))**2) + penalty_const*np.sum((yl - const_par)**2)  + 0*np.abs(np.log(len(x)/len(xi)))*penalty_npoint\n",
    "\n",
    "    res = minimize_scalar(\n",
    "        mse_break,\n",
    "        bounds=(x[min_points], x[-1]),\n",
    "        method='bounded',\n",
    "        options={'maxiter': maxiter}\n",
    "    )\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c08b7",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ALL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f86841",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBulk = False\n",
    "LOAD = True\n",
    "h_slab = 9 # Angstrom\n",
    "\n",
    "\n",
    "\n",
    "# oxid = 0\n",
    "for oxid in [0, 5, 10 ,20 ,40 ,60 ,80]:\n",
    "    c_rep = 0\n",
    "    temps_w = []\n",
    "    temps_g = []\n",
    "    pe_g = []\n",
    "    ke_g = []\n",
    "    etot = []\n",
    "    print(f\" OXID={oxid:3d} \".center(100, \"=\"))\n",
    "    for rep in tqdm(range(1,11), desc='loads reps', total=10) :\n",
    "        try:\n",
    "            root = Path(f'/media/fabiano/b_dev/graphene_oxide-water/transient/{oxid:d}%')\n",
    "            base_remote_path = os.path.join(root, f'Transient/graph{oxid:d}%_{rep:d}')\n",
    "            file_liquid = 'system_h2o.txt'\n",
    "            file_nanoparticles = 'system_graph.txt'\n",
    "            file_chunk = 'temp_chunk_bias_1A.out'\n",
    "            file_slabverify = 'slab_position_verify.txt' \n",
    "            file_Pot = 'potential_graph.txt'\n",
    "            file_Kin = 'kinetic_graph.txt'\n",
    "            temps_g.append(pd.read_csv(os.path.join(base_remote_path, file_nanoparticles), sep=r'\\s+',  skiprows=2, names=[\"step\", f\"temp_{c_rep:d}\"]))\n",
    "            if TBulk:\n",
    "                temps_w.append(pd.read_csv(os.path.join(base_remote_path, file_liquid), sep=r'\\s+', skiprows=2, names=[\"step\", f\"temp_{c_rep:d}\"]))\n",
    "            elif not LOAD: \n",
    "                Tchunks, tot_chunks = read_Tgraph_chunks(base_remote_path, file_chunk, temps_g[0].shape[0])\n",
    "                T_slab_positive, T_slab_negative, T_bulk_chunk, T_slab_mean = process_chunks(Tchunks,tot_chunks,h_slab)\n",
    "                df_slab = pd.DataFrame({\"step\": temps_g[-1][\"step\"].values, f\"temp_{c_rep:d}\": T_slab_mean })\n",
    "                temps_w.append(df_slab)\n",
    "            pe_g.append(pd.read_csv(os.path.join(base_remote_path, file_Pot), sep=r'\\s+', skiprows=2, names=[\"step\", f\"pe_{c_rep:d}\"]))\n",
    "            ke_g.append(pd.read_csv(os.path.join(base_remote_path, file_Kin), sep=r'\\s+', skiprows=2, names=[\"step\", f\"ke_{c_rep:d}\"]))  \n",
    "            etot.append( pd.DataFrame(data={\"step\": pe_g[-1][\"step\"], f\"etot_{c_rep:d}\": pe_g[-1][f\"pe_{c_rep:d}\"] + ke_g[-1][f\"ke_{c_rep:d}\"]}) )\n",
    "            c_rep +=1\n",
    "        except Exception:\n",
    "            print(\"Erro in rep=\", rep)\n",
    "    rep_Tgr = pd.concat(temps_g, axis=1)\n",
    "    rep_etot = pd.concat(etot, axis=1)\n",
    "    numpy_dir = os.path.join(f'{root}','numpy')\n",
    "\n",
    "    if not Path(numpy_dir).exists():\n",
    "            os.mkdir(numpy_dir)\n",
    "\n",
    "    if TBulk:\n",
    "        LOAD = False\n",
    "    if not LOAD:\n",
    "        rep_Tw = pd.concat(temps_w, axis=1)\n",
    "        if not TBulk:\n",
    "            rep_Tw.to_pickle(os.path.join(numpy_dir,f'rep_Tw_{h_slab}A.pkl'))\n",
    "            print(\"saved in: \",os.path.join(numpy_dir,f'rep_Tw_{h_slab}A.pkl'))\n",
    "    else:\n",
    "        rep_Tw = pd.read_pickle(os.path.join(numpy_dir,f'rep_Tw_{h_slab}A.pkl'))\n",
    "\n",
    "    DATA_ALL[oxid] = {\n",
    "        \"Tw\": rep_Tw.copy(),\n",
    "        \"Tgr\": rep_Tgr.copy(),\n",
    "        \"etot\": rep_etot.copy(),\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37246c17",
   "metadata": {},
   "source": [
    "# CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCAT_ALL_DATA = {}\n",
    "N_rep = 10\n",
    "for oxid, data in tqdm(DATA_ALL.items(),desc=\"concat data\", total=len(DATA_ALL)):\n",
    "   \n",
    "    CONCAT_ALL_DATA[oxid] = {\n",
    "        \"time_s\": data[\"Tw\"].iloc[:,0].values * 1e-15, \n",
    "        \"Tw\": np.column_stack([data[\"Tw\"][f\"temp_{i}\"].values for i in range(N_rep)])[5000:],\n",
    "        \"Tgr\": np.column_stack([data[\"Tgr\"][f\"temp_{i}\"].values for i in range(N_rep)])[5000:],\n",
    "        \"etot\": np.column_stack([data[\"etot\"][f\"etot_{i}\"].values for i in range(N_rep)])[5000:]    \n",
    "    }\n",
    "    Nt = CONCAT_ALL_DATA[oxid][\"time_s\"].shape[0]\n",
    "    int_t_rep = np.zeros((Nt, N_rep))\n",
    "    for i in range(N_rep):\n",
    "        dt_i = data[\"Tgr\"].loc[:, f\"temp_{i}\"].values - data[\"Tw\"].loc[:, f\"temp_{i}\"].values\n",
    "        int_t_rep[1:, i] = cumulative_trapezoid(dt_i, CONCAT_ALL_DATA[oxid][\"time_s\"])\n",
    "    CONCAT_ALL_DATA[oxid]['integral'] = int_t_rep[5000:] - int_t_rep[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd0b37",
   "metadata": {},
   "source": [
    "# $R_K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPE_ALL = {}\n",
    "SLOPE_ensavg_ALL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76106f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for oxid, data in CONCAT_ALL_DATA.items():\n",
    "    start_s = time()\n",
    "    print(f\" OX STATE {oxid:3d} \".center(120, \"=\"))\n",
    "    diffT = data['Tgr'] - data['Tw']\n",
    "    integral = data['integral']\n",
    "    etot = data['etot']\n",
    "    scaleT = diffT.std()\n",
    "    scaleE = etot.std()\n",
    "    scaleInt = integral.std()\n",
    "    print(\"searchin t0 ..\", end='')\n",
    "    N_each = integral.shape[0] // 10\n",
    "    t0_all = []\n",
    "    m_all = []\n",
    "    for i in tqdm(range(10), total=10):\n",
    "        t0 = find_breakpoint_iterative(integral[:,i]/scaleInt, etot[:,i]/scaleE, min_points=9, maxiter=500, penalty_npoint=2, penalty_const=1)\n",
    "        integ_temp = integral[:,i]/scaleInt\n",
    "        if len(integ_temp[integ_temp<t0]) < 10:\n",
    "            continue\n",
    "        t0_all.append(t0*scaleInt)\n",
    "        # m_all.append(m)\n",
    "    print(\"done!\")\n",
    "    print(f\"\\t t0={t0:1.3e}\")\n",
    "    t0_min = np.min(t0_all)\n",
    "\n",
    "    print(f\"t0_min = {t0_min:1.3e}\")\n",
    "    print(\"linear fit ..\", end='')\n",
    "    x_fit = integral[integral<t0_min]\n",
    "    y_fit = etot[integral<t0_min]\n",
    "    x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "    robust_model = sm.OLS(y_fit, x_fit)\n",
    "    results = robust_model.fit()\n",
    "    slope = results.params[1]\n",
    "    slope_reps = []\n",
    "    all_fit = []\n",
    "    for i in tqdm(range(10), total=10):\n",
    "        integral_rep = integral[:,i]\n",
    "        etot_rep = etot[:,i]\n",
    "        t0_i = t0_all[i] \n",
    "        x_fit = integral_rep[integral_rep<t0_min]\n",
    "        y_fit = etot_rep[integral_rep<t0_min]\n",
    "        x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "        robust_model = sm.OLS(y_fit, x_fit)\n",
    "        results_rep = robust_model.fit()\n",
    "        all_fit.append(\n",
    "            results_rep\n",
    "        )\n",
    "        slope_reps.append( results_rep.params[1] )\n",
    "\n",
    "    intercept_reps = [res.params[0] for res in all_fit]\n",
    "    slope_reps     = [res.params[1] for res in all_fit]\n",
    "    a_bar = np.mean(intercept_reps)\n",
    "    m_bar = np.mean(slope_reps)\n",
    "    x_pred = np.linspace(integral.min(), t0_min, 100)\n",
    "    y_med = a_bar + m_bar * x_pred\n",
    "    plt.plot(x_pred, y_med, color='r', zorder =20 , lw=4)\n",
    "\n",
    "    # slope_err = results.bse[1]\n",
    "    # slope_err = np.std(slope_reps) * 1.96\n",
    "    slope = np.mean(slope_reps)\n",
    "\n",
    "    N_rep = len(slope_reps)          # 10\n",
    "    slope_se   = np.std(slope_reps, ddof=1) / np.sqrt(N_rep)   # standard error\n",
    "    slope_err  = 1.96 * slope_se \n",
    "    \n",
    "        \n",
    "    # }\n",
    "    SLOPE_ALL[oxid] = {\n",
    "        \"Rk_m\" : - AREA[oxid]/ (slope* 4184 / N_A),\n",
    "        \"Rk_e\" : AREA[oxid]/ (4184 / N_A) / (slope)**2 * slope_err,\n",
    "    }\n",
    "    \n",
    "    SLOPE_ALL[oxid][\"Rk_rse\"] = SLOPE_ALL[oxid][\"Rk_e\"] / abs(SLOPE_ALL[oxid][\"Rk_m\"])\n",
    "    SLOPE_ALL[oxid][\"Gk_m\"] = 1/SLOPE_ALL[oxid][\"Rk_m\"]\n",
    "    SLOPE_ALL[oxid][\"Gk_e\"] = SLOPE_ALL[oxid][\"Rk_e\"] / SLOPE_ALL[oxid][\"Rk_m\"]**2\n",
    "    print(f\"\\t m = {slope:1.3e} +/- {slope_err:1.3e}\")\n",
    "    print(f\"\\t Rk = {SLOPE_ALL[oxid][\"Rk_m\"]:1.3e} +/- {SLOPE_ALL[oxid][\"Rk_e\"]:1.3e} (i.e )  {SLOPE_ALL[oxid][\"Rk_rse\"]}\")\n",
    "    print(f\"\\t Gk = {SLOPE_ALL[oxid][\"Gk_m\"]:1.3e} +/- {SLOPE_ALL[oxid][\"Gk_e\"]:1.3e}\")\n",
    "    b = results.params\n",
    "    x_pred = np.linspace(integral.min(), t0_min, 10)\n",
    "    pred = results.get_prediction(sm.add_constant(x_pred))\n",
    "    y_pred = pred.predicted\n",
    "    iv_l_ols = pred.summary_frame()[\"mean_ci_lower\"]\n",
    "    iv_u_ols = pred.summary_frame()[\"mean_ci_upper\"]\n",
    "    print(\"done!\")\n",
    "\n",
    "    # plot\n",
    "    indx0  = np.where(integral[:,0]<t0_min)[0]\n",
    "    int_rep_mean = integral[indx0, :].mean(axis=1)\n",
    "    etot_mean = etot[indx0, :].mean(axis=1)\n",
    "    plt.plot(int_rep_mean,etot_mean, color='y')\n",
    "\n",
    "    slope_ensam_avg = - AREA[oxid]/ (np.polyfit(int_rep_mean,etot_mean,1)[0] * 4184 / N_A)\n",
    "    print(f\"R_ens_avg = {slope_ensam_avg}\")\n",
    "    SLOPE_ensavg_ALL[oxid] = {\n",
    "        \"Rk_m\" : - AREA[oxid]/ (slope* 4184 / N_A)  \n",
    "    }\n",
    "    SLOPE_ensavg_ALL[oxid][\"Gk_m\"] = 1/SLOPE_ensavg_ALL[oxid][\"Rk_m\"]\n",
    "    n=0\n",
    "    for res_fint in all_fit:\n",
    "        indx0 = integral[:, n] < t0_min\n",
    "        pred = res_fint.get_prediction(sm.add_constant(x_pred))\n",
    "        y_pred_i = pred.predicted\n",
    "        plt.plot(x_pred,y_pred_i, color='k', ls=\":\")\n",
    "        plt.scatter(integral[indx0,n], etot[indx0,n], s=4, alpha=.3, label = f'Replicate {n}')\n",
    "        n += 1\n",
    "    # plt.legend(loc='best', fontsize='small')    \n",
    "    plt.show()\n",
    "    # plt.xlim(integral.min(), t0_min)\n",
    "    end_time =  time()\n",
    "    print(f\"elalpesed time {end_time-start_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = [[oxid, data[\"Gk_m\"], data[\"Gk_e\"]] for oxid, data in SLOPE_ALL.items()]\n",
    "data_all = np.asarray(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.errorbar(data_all[:,0], data_all[:,1], yerr=data_all[:,2],)\n",
    "# plt.scatter(data_all[:,0], data_all[:,1],c='b',marker='o')\n",
    "x_fit = data_all[:,0]\n",
    "y_fit = data_all[:,1]\n",
    "x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "weight = data_all[:,1]**2/data_all[:,2]**2\n",
    "weight /= weight.mean()\n",
    "robust_model = sm.GLM(y_fit, x_fit, var_weights=weight)\n",
    "results = robust_model.fit()\n",
    "x_pred = np.linspace(data_all[:,0].min(), data_all[:,0].max(), 100)\n",
    "pred = results.get_prediction(sm.add_constant(x_pred))\n",
    "y_pred = pred.predicted\n",
    "iv_l_ols = pred.summary_frame()[\"mean_ci_lower\"]\n",
    "iv_u_ols = pred.summary_frame()[\"mean_ci_upper\"]\n",
    "# plt.fill_between(x_pred, iv_l_ols, iv_u_ols, alpha=.3, color='k')\n",
    "# plt.plot(x_pred, y_pred, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8490d",
   "metadata": {},
   "source": [
    "# ensamble average test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd606898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of Gk averaging energy and temperatures among simulations before calculating the slopes \n",
    "RUN = False\n",
    "if RUN:\n",
    "    data_ensavg_all = [[oxid, data[\"Gk_m\"]] for oxid, data in SLOPE_ensavg_ALL.items()]\n",
    "    data_all = np.asarray(data_ensavg_all)\n",
    "    data_all = data_all[:,0:2]\n",
    "    data_all\n",
    "\n",
    "    plt.scatter(data_all[:,0], data_all[:,1],c='b',marker='o')\n",
    "    x_fit = data_all[:,0]\n",
    "    y_fit = data_all[:,1]\n",
    "    x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "\n",
    "    robust_model = sm.GLM(y_fit, x_fit)\n",
    "    results = robust_model.fit()\n",
    "\n",
    "    x_pred = np.linspace(data_all[:,0].min(), data_all[:,0].max(), 100)\n",
    "    pred = results.get_prediction(sm.add_constant(x_pred))\n",
    "    y_pred = pred.predicted\n",
    "    iv_l_ols = pred.summary_frame()[\"mean_ci_lower\"]\n",
    "    iv_u_ols = pred.summary_frame()[\"mean_ci_upper\"]\n",
    "    plt.fill_between(x_pred, iv_l_ols, iv_u_ols, alpha=.3, color='k')\n",
    "    plt.plot(x_pred, y_pred, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd09da3",
   "metadata": {},
   "source": [
    "# Paper Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435c331",
   "metadata": {},
   "source": [
    "## Gk vs oxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleup = 1.25\n",
    "fig = plt.figure(figsize=(3.3*scaleup, 2*scaleup), dpi=250)\n",
    "\n",
    "with plt.style.context(\"/home/fabiano/WORK/style.matplot\"):\n",
    "    grid = fig.add_gridspec(1,1, top=.99, right=.99, bottom=.18)\n",
    "    ax = fig.add_subplot(grid[0] )\n",
    "    # plt.fill_between(df[\"time\"], df[\"CA\"]-df[\"std\"], df[\"CA\"]+df[\"std\"], alpha=.5)\n",
    "    plt1 = ax.errorbar(data_all[:,0], data_all[:,1]*1e-8, yerr=data_all[:,2]*1e-8, capsize=2.2, fmt='o', markersize=3.2, zorder=11, color=\"#282222\", lw=.5, label=\"Instantaneous value\")\n",
    "    plt2 = ax.fill_between(x_pred, iv_l_ols*1e-8, iv_u_ols*1e-8, alpha=.4, zorder=10, color=\"#5678E7\")\n",
    "    plt3 = ax.plot(x_pred, y_pred*1e-8, '-', lw=1.3, zorder=10, color='#5678E7')\n",
    "    ax.legend([plt1, (plt2,plt3[0])], (\"Simulation Data\", \"Linear regression (with 95% CB)\"))\n",
    "    ax.set_xlabel(\"Oxidation (%)\")\n",
    "    \n",
    "    ax.set_ylabel(r\"$\\mathregular{1/R_k}$ (x10$^8$ W/m$^2$K)\")\n",
    "fig.savefig(\"/home/fabiano/graphtmp/plot_article/fig_Gk-oxid.png\", dpi=400)\n",
    "fig.savefig(\"/home/fabiano/graphtmp/plot_article/fig_Gk-oxid.pdf\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c4cdd",
   "metadata": {},
   "source": [
    "## Slopes (suppy: S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oxid = int(10)\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "for oxid, data in CONCAT_ALL_DATA.items():\n",
    "    print(f\" OX STATE {oxid:3d} \".center(120, \"=\"))\n",
    "    diffT = data['Tgr'] - data['Tw']\n",
    "    integral = data['integral']\n",
    "    etot = data['etot']\n",
    "    scaleT = diffT.std()\n",
    "    scaleE = etot.std()\n",
    "    scaleInt = integral.std()\n",
    "    N_each = integral.shape[0] // 10\n",
    "    t0_all = []\n",
    "    m_all = []\n",
    "    for i in tqdm(range(10), total=10):\n",
    "        t0 = find_breakpoint_iterative(integral[:,i]/scaleInt, etot[:,i]/scaleE, min_points=9, maxiter=500, penalty_npoint=2, penalty_const=1)\n",
    "        integ_temp = integral[:,i]/scaleInt\n",
    "        if len(integ_temp[integ_temp<t0]) < 10:\n",
    "            continue\n",
    "        t0_all.append(t0*scaleInt)\n",
    "    t0_min = np.min(t0_all) \n",
    "    print(f\"t0_min = {t0_min:1.3e}\")\n",
    "    print(\"linear fit ..\", end='')\n",
    "    x_fit = integral[integral<t0_min]\n",
    "    y_fit = etot[integral<t0_min]\n",
    "    x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "    robust_model = sm.OLS(y_fit, x_fit)\n",
    "    results = robust_model.fit()\n",
    "    slope = results.params[1]\n",
    "    slope_reps = []\n",
    "    all_fit = []\n",
    "    for i in tqdm(range(10), total=10):\n",
    "        integral_rep = integral[:,i]\n",
    "        etot_rep = etot[:,i]\n",
    "        t0_i = t0_all[i]\n",
    "        x_fit = integral_rep[integral_rep<t0_min]\n",
    "        y_fit = etot_rep[integral_rep<t0_min]\n",
    "        x_fit = sm.add_constant(x_fit)  # Adds a constant term to the predictor\n",
    "        robust_model = sm.OLS(y_fit, x_fit)\n",
    "        results_rep = robust_model.fit()\n",
    "        all_fit.append(\n",
    "            results_rep\n",
    "        )\n",
    "        slope_reps.append( results_rep.params[1] )\n",
    "        \n",
    "\n",
    "    slope = np.mean(slope_reps)\n",
    "\n",
    "    N_rep = len(slope_reps)          # 10\n",
    "    slope_se   = np.std(slope_reps, ddof=1) / np.sqrt(N_rep)   # standard error\n",
    "    slope_err  = 1.96 * slope_se \n",
    "\n",
    "        \n",
    "    # }\n",
    "    SLOPE_ALL[oxid] = {\n",
    "        \"Rk_m\" : - AREA[oxid]/ (slope* 4184 / N_A),\n",
    "        \"Rk_e\" : AREA[oxid]/ (4184 / N_A) / (slope)**2 * slope_err,\n",
    "    }\n",
    "\n",
    "    SLOPE_ALL[oxid][\"Rk_rse\"] = SLOPE_ALL[oxid][\"Rk_e\"] / abs(SLOPE_ALL[oxid][\"Rk_m\"])\n",
    "    SLOPE_ALL[oxid][\"Gk_m\"] = 1/SLOPE_ALL[oxid][\"Rk_m\"]\n",
    "    SLOPE_ALL[oxid][\"Gk_e\"] = SLOPE_ALL[oxid][\"Rk_e\"] / SLOPE_ALL[oxid][\"Rk_m\"]**2\n",
    "    print(f\"\\t m = {slope:1.3e} +/- {slope_err:1.3e}\")\n",
    "    print(f\"\\t Rk = {SLOPE_ALL[oxid][\"Rk_m\"]:1.3e} +/- {SLOPE_ALL[oxid][\"Rk_e\"]:1.3e}\")\n",
    "    print(f\"\\t Gk = {SLOPE_ALL[oxid][\"Gk_m\"]:1.3e} +/- {SLOPE_ALL[oxid][\"Gk_e\"]:1.3e}\")\n",
    "    b = results.params\n",
    "    x_pred = np.linspace(integral.min(), t0_min, 10)\n",
    "    pred = results.get_prediction(sm.add_constant(x_pred))\n",
    "    y_pred = pred.predicted\n",
    "    iv_l_ols = pred.summary_frame()[\"mean_ci_lower\"]\n",
    "    iv_u_ols = pred.summary_frame()[\"mean_ci_upper\"]\n",
    "\n",
    "    # Plot\n",
    "    indx0  = np.where(integral[:,0]<t0_min)[0]\n",
    "    fig = plt.figure(figsize=(3, 1.7), dpi=200)\n",
    "\n",
    "    with plt.style.context(\"/home/fabiano/WORK/style.matplot\"):\n",
    "        grid = fig.add_gridspec(1,16,  bottom=.28, left=.23, top=.985, right=.86)\n",
    "        ax = fig.add_subplot(grid[:-1])\n",
    "        ax_bar = fig.add_subplot(grid[-1])\n",
    "\n",
    "        \n",
    "        # plot mean of linear regressions\n",
    "        n_fits  =10\n",
    "        palette = sns.color_palette(\"blend:#ffe6cc,#e6a1a1,#aa8fcc\", n_colors=n_fits)\n",
    "        cmap    = mcolors.ListedColormap(palette)\n",
    "        bounds  = np.arange(n_fits + 1)            # [0,1,2,...,n_fits]\n",
    "        norm    = mcolors.BoundaryNorm(bounds, n_fits)\n",
    "\n",
    "        # --- a ScalarMappable just for the colorbar ---\n",
    "        mappable = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        mappable.set_array([])\n",
    "                \n",
    "        intercept_reps = [res.params[0] for res in all_fit]\n",
    "        slope_reps     = [res.params[1] for res in all_fit]\n",
    "        a_bar = np.mean(intercept_reps)\n",
    "        m_bar = np.mean(slope_reps)\n",
    "        x_pred = np.linspace(integral.min(), t0_min, 100)\n",
    "        y_med = a_bar + m_bar * x_pred\n",
    "        \n",
    "        n=0\n",
    "        size = .75 \n",
    "        alpha = 1.0 \n",
    "        \n",
    "        for res_fint in all_fit:\n",
    "            this_color = cmap(n)\n",
    "            pred = res_fint.get_prediction(sm.add_constant(x_pred))\n",
    "            y_pred_i = pred.predicted\n",
    "            mask_n = integral[:, n] < t0_min\n",
    "            plt0 = ax.plot(x_pred*1e9,y_pred_i*1e-3, color=\"#000000\", ls=\":\", lw=.8, zorder=100)\n",
    "            ax.plot(integral[mask_n,n]*1e9, etot[mask_n,n]*1e-3, lw=size, alpha=alpha, color=this_color)\n",
    "            n += 1\n",
    "        plt1 = ax.plot(x_pred*1e9, y_med*1e-3, color=\"#B40000\", zorder =120 , lw=1.5)\n",
    "        ax.set_xlabel(r'$\\int\\Delta T \\, \\mathrm{d}t$ $\\mathrm{(K\\cdot ns)}$')\n",
    "        ax.set_ylabel(\"Energy $\\mathrm{(Mcal / mol)}$\")\n",
    "        # ax.legend([plt0[0], plt1[0]], (\"Single linear fit\", \"Average linear fit\"), loc=\"lower center\", bbox_to_anchor=[0.5, 0.96] )\n",
    "        cbar = fig.colorbar(mappable,\n",
    "                    cax=ax_bar,\n",
    "                    boundaries=bounds,\n",
    "                    ticks=bounds[:-1] + 0.5,  # centers of each bin\n",
    "                    spacing='uniform')        # equalâ€sized boxes\n",
    "        cbar.set_ticklabels(np.arange(1, n_fits+1))  \n",
    "        cbar.set_label('Replica ID')\n",
    "        cbar.ax.yaxis.set_tick_params('both', width=0.0)\n",
    "        ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.1f}'))\n",
    "        fig.savefig(f\"/home/fabiano/graphtmp/plot_article/fig_slopes-oxid{oxid:02d}.png\", dpi=400)\n",
    "        fig.savefig(f\"/home/fabiano/graphtmp/plot_article/fig_slopes-oxid{oxid:02d}.pdf\", dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crea una figura solo con la legenda\n",
    "fig, ax = plt.subplots(figsize=(3.3, 2), dpi=250)\n",
    "\n",
    "# Simuliamo le linee per la legenda\n",
    "linea_media, = ax.plot([], [], color=\"#B40000\", lw=3, label=\"Ensemble-average OLS fit\")\n",
    "linea_i, = ax.plot([], [], color='#3A445D', ls=\":\", lw=1, label=\"Individual OLS fit\")\n",
    "scatter_i = ax.scatter([], [], s=10, alpha=0.4, c='#9E0142', label=\"\")  # un colore qualsiasi dalla palette\n",
    "\n",
    "# Costruisci la legenda\n",
    "handles = [linea_media, linea_i, scatter_i]\n",
    "labels = [\"Ensemble-average OLS fit\", \"Individual OLS fit\", \"\"]  # Terzo label vuoto per non duplicare\n",
    "ax.legend(handles=handles[:2], labels=labels[:2], loc='center')\n",
    "ax.axis('off')  # nascondi assi\n",
    "\n",
    "# Salva o mostra la figura\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"legend_only.pdf\", dpi=400)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
